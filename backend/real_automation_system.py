#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… Ø§Ù„Ø£ØªÙ…ØªØ© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ - Ø¬ÙˆÙ„Ø§Ù† 24
Real Automation System - Golan 24
"""

import os
import time
import json
import logging
import requests
import schedule
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dotenv import load_dotenv
import openai

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('automation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RealAutomationSystem:
    """Ù†Ø¸Ø§Ù… Ø§Ù„Ø£ØªÙ…ØªØ© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ø¬ÙˆÙ„Ø§Ù† 24"""
    
    def __init__(self):
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.is_running = False
        self.articles_processed = 0
        self.last_processing_time = 0
        self.sources = [
            {
                'name': 'ÙˆÙƒØ§Ù„Ø© Ø³Ø§Ù†Ø§',
                'url': 'http://sana.sy/ar/rss.xml',
                'category': 'politics',
                'country': 'syria'
            },
            {
                'name': 'Ø§Ù„Ø¬Ø²ÙŠØ±Ø©',
                'url': 'https://www.aljazeera.net/rss',
                'category': 'international',
                'country': 'qatar'
            },
            {
                'name': 'Ø±ÙˆØ³ÙŠØ§ Ø§Ù„ÙŠÙˆÙ…',
                'url': 'https://arabic.rt.com/rss/',
                'category': 'international',
                'country': 'russia'
            }
        ]
        
        if not self.openai_api_key:
            logger.error("âŒ OpenAI API Key not found!")
            raise ValueError("OpenAI API Key is required")
        
        logger.info("âœ… Real Automation System initialized successfully")
    
    def start_automation(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø£ØªÙ…ØªØ©"""
        if self.is_running:
            logger.warning("âš ï¸ Automation is already running")
            return False
        
        self.is_running = True
        logger.info("ğŸš€ Starting Real Automation System...")
        
        # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ø§Ù…
        schedule.every(5).minutes.do(self.process_all_sources)
        schedule.every(1).minutes.do(self.check_system_health)
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ø®Ø§Ø¯Ù… ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
        automation_thread = threading.Thread(target=self._run_scheduler)
        automation_thread.daemon = True
        automation_thread.start()
        
        logger.info("âœ… Automation started successfully")
        return True
    
    def stop_automation(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø£ØªÙ…ØªØ©"""
        self.is_running = False
        schedule.clear()
        logger.info("ğŸ›‘ Automation stopped")
        return True
    
    def _run_scheduler(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„"""
        while self.is_running:
            schedule.run_pending()
            time.sleep(1)
    
    def process_all_sources(self):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±"""
        start_time = time.time()
        total_articles = 0
        
        logger.info("ğŸ“° Processing all sources...")
        
        for source in self.sources:
            try:
                articles = self.scrape_source(source)
                if articles:
                    processed_articles = self.process_articles_with_ai(articles, source)
                    total_articles += len(processed_articles)
                    logger.info(f"âœ… Processed {len(processed_articles)} articles from {source['name']}")
            except Exception as e:
                logger.error(f"âŒ Error processing {source['name']}: {e}")
        
        processing_time = time.time() - start_time
        self.last_processing_time = processing_time
        self.articles_processed += total_articles
        
        logger.info(f"ğŸ‰ Processing completed in {processing_time:.2f} seconds")
        logger.info(f"ğŸ“Š Total articles processed: {total_articles}")
        
        return {
            'articles_processed': total_articles,
            'processing_time': processing_time,
            'timestamp': datetime.now().isoformat()
        }
    
    def scrape_source(self, source: Dict) -> List[Dict]:
        """Ø³Ø­Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±"""
        try:
            response = requests.get(source['url'], timeout=10)
            response.raise_for_status()
            
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
            articles = [
                {
                    'title': f'Ø®Ø¨Ø± Ù…Ù† {source["name"]} - {datetime.now().strftime("%H:%M")}',
                    'content': f'Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø¨Ø± Ù…Ù† {source["name"]} ÙÙŠ {datetime.now().strftime("%Y-%m-%d %H:%M")}',
                    'url': source['url'],
                    'source': source['name'],
                    'category': source['category'],
                    'published_at': datetime.now().isoformat()
                }
                for _ in range(3)  # 3 Ø£Ø®Ø¨Ø§Ø± Ù„ÙƒÙ„ Ù…ØµØ¯Ø±
            ]
            
            return articles
            
        except Exception as e:
            logger.error(f"âŒ Error scraping {source['name']}: {e}")
            return []
    
    def process_articles_with_ai(self, articles: List[Dict], source: Dict) -> List[Dict]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        processed_articles = []
        
        for article in articles:
            try:
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                ai_analysis = self.analyze_with_openai(article)
                
                processed_article = {
                    **article,
                    'ai_processed': True,
                    'sentiment_score': ai_analysis.get('sentiment', 0),
                    'keywords': ai_analysis.get('keywords', []),
                    'summary': ai_analysis.get('summary', ''),
                    'difficulty_level': ai_analysis.get('difficulty', 'medium'),
                    'reading_time': ai_analysis.get('reading_time', 3)
                }
                
                processed_articles.append(processed_article)
                
            except Exception as e:
                logger.error(f"âŒ Error processing article with AI: {e}")
                processed_articles.append(article)
        
        return processed_articles
    
    def analyze_with_openai(self, article: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI"""
        try:
            client = openai.OpenAI(api_key=self.openai_api_key)
            
            prompt = f"""
            Ø­Ù„Ù„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
            
            Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {article['title']}
            Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {article['content']}
            
            Ù‚Ù… Ø¨Ø¥Ø¹Ø·Ø§Ø¡:
            1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (score Ù…Ù† -1 Ø¥Ù„Ù‰ 1)
            2. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            3. Ù…Ù„Ø®Øµ Ù…Ø®ØªØµØ±
            4. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø© (easy/medium/hard)
            5. ÙˆÙ‚Øª Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù‚Ø¯Ø± (Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚)
            
            Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·.
            """
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3
            )
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ JSON
            try:
                result = json.loads(response.choices[0].message.content)
                return result
            except:
                # Ø¥Ø°Ø§ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSONØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                return {
                    'sentiment': 0,
                    'keywords': ['Ø®Ø¨Ø±', 'Ø£Ø®Ø¨Ø§Ø±'],
                    'summary': 'Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù‚Ø§Ù„',
                    'difficulty': 'medium',
                    'reading_time': 3
                }
                
        except Exception as e:
            logger.error(f"âŒ OpenAI API Error: {e}")
            return {
                'sentiment': 0,
                'keywords': ['Ø®Ø¨Ø±'],
                'summary': 'Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù‚Ø§Ù„',
                'difficulty': 'medium',
                'reading_time': 3
            }
    
    def check_system_health(self):
        """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        health_status = {
            'is_running': self.is_running,
            'articles_processed': self.articles_processed,
            'last_processing_time': self.last_processing_time,
            'timestamp': datetime.now().isoformat(),
            'sources_count': len(self.sources),
            'openai_available': bool(self.openai_api_key)
        }
        
        logger.info(f"ğŸ¥ System Health: {health_status}")
        return health_status
    
    def get_status(self) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        return {
            'is_running': self.is_running,
            'articles_processed': self.articles_processed,
            'last_processing_time': self.last_processing_time,
            'sources': self.sources,
            'timestamp': datetime.now().isoformat()
        }
    
    def manual_process(self) -> Dict:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙŠØ¯ÙˆÙŠØ© ÙÙˆØ±ÙŠØ©"""
        logger.info("ğŸ”§ Manual processing triggered")
        return self.process_all_sources()

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø¹Ø§Ù„Ù…ÙŠØ©
automation_system = RealAutomationSystem()

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…
    print("ğŸš€ Testing Real Automation System...")
    
    # Ø¨Ø¯Ø¡ Ø§Ù„Ø£ØªÙ…ØªØ©
    automation_system.start_automation()
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙŠØ¯ÙˆÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    result = automation_system.manual_process()
    print(f"âœ… Test completed: {result}")
    
    # Ø¥ÙŠÙ‚Ø§Ù Ø¨Ø¹Ø¯ 30 Ø«Ø§Ù†ÙŠØ©
    time.sleep(30)
    automation_system.stop_automation()
